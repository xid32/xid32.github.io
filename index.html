<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="./index.css">
  <link rel="icon" type="image/png" href="images/dartmouth_logo.jpeg">
  <title>Xingjian Diao</title>
</head>
<body>

  <div class="content" style="display: block;">
    <nav class="nav1-show">
      <a href="index.html"><h2 class="title">Xingjian's Website</h2></a>
      <ul class="nav-ul">
        <li class="nav-item"><a href="#">Biography</a></li>
        <li class="nav-item"><a href="#Publications">Publications</a></li>
        <li class="nav-item"><a href="#Projects">Projects</a></li>
        <li class="nav-item"><a href="#Teaching">Teaching</a></li>
        <li class="nav-item"><a href="#Services">Services</a></li>
        <li class="nav-item"><a href="#Contact">Contact</a></li>
      </ul>
    </nav>

    <nav class="nav2-show">
      <a href="index.html"><h2 class="title">Xingjian's Website</h2></a>
    </nav>
    
    <ul class="mobile-nav">
      <li class="nav-item"><strong><a style="color:#4169E1; text-decoration: none;" href="#Publications">Publications</a></strong></li>
      <li class="nav-item"><strong><a style="color:#4169E1; text-decoration: none;" href="#Projects">Projects</a></strong></li>
      <li class="nav-item"><strong><a style="color:#4169E1; text-decoration: none;" href="#Teaching">Teaching</a></strong></li>
      <li class="nav-item"><strong><a style="color:#4169E1; text-decoration: none;" href="#Services">Services</a></strong></li>
    </ul>

    <!-- <ul class="nav-ul mobile-nav">
      <li class="nav-item"> <strong><a style="color:#4169E1; text-decoration: none;" href="#Publications">Publications</a></strong></li>
      <li class="nav-item"> <strong><a style="color:#4169E1; text-decoration: none;" href="#Projects">Projects</a></strong></li>
       <li class="nav-item"> <strong><a style="color:#4169E1; text-decoration: none;" href="#Teaching">Teaching</a></strong></li>
       <li class="nav-item"> <strong><a style="color:#4169E1; text-decoration: none;" href="#Services">Services</a></strong></li>
    </ul> -->
    
    <section class="body">
      <div class="left">
        <div class="head-img"></div>
        <h1 class="name">Xingjian Diao</h1>
      
        <ul class="icon">
          <li class="icon-item"><a href="mailto:xingjian.diao.gr@dartmouth.edu"><img src="./svg_icons/email-svgrepo-com.svg" alt=""></a></li>
          <li class="icon-item"><img src="./svg_icons/icons8-linkedin.svg" alt="" onclick="window.location.href='http:\/\/www.linkedin.com/in/xingjian-diao-a5637814a/'"></li>
          <!-- <li class="icon-item"><img src="./svg_icons/researchgate-logo-svgrepo-com.svg" alt="" onclick="window.location.href='http:\/\/researchgate.net/profile/Xingjian_Diao/'"></li> -->
          <li class="icon-item"><img src="./svg_icons/icons8-google-scholar.svg" alt="" onclick="window.location.href='https:\/\/scholar.google.com/citations?user=-U2KzpYAAAAJ&hl=en'"></li>
          <!-- <li class="icon-item"><img src="./svg_icons/curriculum-vitae-resume-svgrepo-com.svg" alt="" onclick="window.location.href='./Xingjian_CV.pdf'" ></li> -->

        </ul>
      </div>
      <div class="right">
        <h1 class="biography-title">About Me</h1>
        <br><br>
        <section class="biography">
          
        <p>I am currently a Ph.D. student at <a href="https://web.cs.dartmouth.edu/" style="color:#4169E1; text-decoration: none;">Dartmouth College</a>. 
          My research interests focus on <strong>multimodal learning</strong>. 
          I have published papers and developed codes for 
          temporal modeling, efficient training, and audio-video-language integration, advancing state-of-the-art 
          <strong>multimodal large language models</strong> (MLLMs) applications such as multimodal question answering. During my Ph.D. studies, I interned at Amazon <img src="images/amazon_logo.png" width = "25" height = "25" align=center /> as an Applied Scientist in 2025.</p>
          
        <br><p>Prior to Dartmouth, I earned a Master's degree in Computer Science from Northwestern University (2021), advised by Prof. <a href="https://habitslab.github.io/" style="color:#4169E1; text-decoration: none;">Nabil Alshurafa</a> (<span style="color: #e141cc;">Thank you, Nabil!</span>), and a B.S. degree in Computer Science from the University of Pittsburgh (2020).</p>

      </section>
      </div>
    </section>


</section>


<section id="News" class="showcase">
  <div class="showcase-left">
    <div class="showcase-left-title">News</div>
    <div class="showcase-left-desc">Recent News</div>
  </div>

  <div class="showcase-right">

<style>
  /* Âè™‰ΩúÁî®‰∫é NewsÔºåÁÆÄÊ¥Å‰ΩÜÊéíÁâàËàíÊúç */
  #News .news-plain {
    list-style: none;
    margin: 0;
    padding: 0;
    font-size: 16px;
    line-height: 1.55;
  }
  #News .news-plain li {
    display: flex;
    align-items: flex-start;
    padding: 6px 0;
    border-bottom: 1px solid #e6e6e6;
  }
  #News .news-plain li:last-child {
    border-bottom: 0;
  }
  #News .news-plain .date {
    font-weight: 700;
    color: #1b6535;
    white-space: nowrap;
    margin-right: 14px; /* üåø Á®çÂæÆÁ©∫‰∏ÄÁÇπÔºåËßÜËßâÊõ¥Âπ≥Ë°° */
  }
</style>

<ul class="news-plain">
  <li>
    <span class="date">Sep 2025:</span>
    <span>Finished my internship as an Applied Scientist at Amazon. Grateful to my mentor, manager, and all collaborators for the invaluable experience!</span>
  </li>
  <li>
    <span class="date">Aug 2025:</span>
    <span>
      Four papers accepted to EMNLP 2025 (two first-author papers selected as
      <font color="#E55C5C">oral presentations</font>).
      Thanks to my excellent collaborators. See you in Suzhou!
    </span>
  </li>
  <li>
    <span class="date">May 2025:</span>
    <span>One first-author paper accepted at ACL 2025. Thanks to my excellent collaborators. See you in Vienna!</span>
  </li>
  <li>
    <span class="date">Jan 2025:</span>
    <span>One first-author paper accepted to NAACL 2025. Thanks to my excellent collaborators. See you in Albuquerque!</span>
  </li>
  <li>
    <span class="date">Oct 2024:</span>
    <span>One first-author paper accepted at WACV 2025. Thanks to my excellent collaborators. See you in Tucson!</span>
  </li>
</ul>



  </div>
</section>


      </div>
    </section>

    <section id="Publications" class="showcase">
      <div class="showcase-left">
        <div class="showcase-left-title">Publications</div>
        <div class="showcase-left-desc">Selected Publications</div>
        <div class="footnote">
            <!-- <p><sup>*</sup> indicates equal contribution</p> -->
        </div>
      </div>
      <div class="showcase-right">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


             <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/SoundMind.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2506.12935" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>SoundMind: RL-Incentivized Logic Reasoning for Audio-Language Models</papertitle>
                </a>
                <br>
                <strong>Xingjian Diao</strong>, Chunhui Zhang, Keyi Kong, Weiyi Wu, Chiyu Ma, Zhongyu Ouyang, Peijun Qing, Soroush Vosoughi, Jiang Gui
                <br>
                <em>Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2025 <font color="#E55C5C"><strong>(Oral Presentation)</strong></font>
              </td>
            </tr>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/vlas.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2509.16680" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>ProtoVQA: An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering</papertitle>
                </a>
                <br>
                <strong>Xingjian Diao</strong><sup>*</sup>, Weiyi Wu<sup>*</sup>, Keyi Kong, Peijun Qing, Xinwen Xu, Ming Cheng, Soroush Vosoughi, Jiang Gui
                <br>
                <em>Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2025 <font color="#E55C5C"><strong>(Oral Presentation)</strong></font>
              </td>
            </tr>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/Hierarchical.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>Knowing More, Acting Better: Hierarchical Representation for Embodied Decision-Making</papertitle>
                </a>
                <br>
                Chunhui Zhang, Zhongyu Ouyang, <strong>Xingjian Diao</strong>, Zheyuan Liu, Soroush Vosoughi
                <br>
                <em>Conference on Empirical Methods in Natural Language Processing (EMNLP 2025) Findings</em>
              </td>
            </tr>



            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/Medllm.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2505.07968" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>Assessing and Mitigating Medical Knowledge Drift and Conflicts in Large Language Models</papertitle>
                </a>
                <br>
                Weiyi Wu, Xinwen Xu, Chongyang Gao, <strong>Xingjian Diao</strong>, Siting Li, Lucas A Salas, Jiang Gui
                <br>
                <em>Conference on Empirical Methods in Natural Language Processing (EMNLP 2025) Findings</em>
              </td>
            </tr>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/TWM.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://aclanthology.org/2025.findings-naacl.189.pdf" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>Temporal Working Memory: Query-Guided Temporal Segment Refinement for Enhanced Multimodal Understanding</papertitle>
                </a>
                <br>
                <strong>Xingjian Diao</strong><sup>*</sup>, Chunhui Zhang<sup>*</sup>, Weiyi Wu, 
                Zhongyu Ouyang, Peijun Qing, Ming Cheng, Soroush Vosoughi, Jiang Gui
                <br>
                <em>Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2025) Findings</em>
                <br>
                <span style="color: gold; font-size: 24px;">&#x1F396; </span> <span style="color: 	#DAA520; font-size: 15px;">Guarini School of Graduate and Advanced Studies Travel Award, Dartmouth College</span>
              </td>
            </tr>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/Sparsify.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2506.01319" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>Learning Sparsity for Effective and Efficient Music Performance Question Answering</papertitle>
                </a>
                <br>
                <strong>Xingjian Diao</strong>, Tianzhen Yang, Chunhui Zhang, Weiyi Wu, Ming Cheng, Jiang Gui
                <br>
                <em>Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2025
              </td>
            </tr>


              <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/FT2TF.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://openaccess.thecvf.com/content/WACV2025/papers/Diao_FT2TF_First-Person_Statement_Text-To-Talking_Face_Generation_WACV_2025_paper.pdf" style="color:#4169E1; text-decoration: none;">
                  <papertitle>FT2TF: First-Person Statement Text-To-Talking Face Generation</papertitle>
                </a>
                <br>
                <strong>Xingjian Diao</strong>, Ming Cheng, Wayner Barrios, SouYoung Jin
                <br>
                <em>Winter Conference on Applications of Computer Vision (WACV)</em>, 2025
              </td>
            </tr>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/span.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2406.09333" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>SPAN: Unlocking Pyramid Representations for Gigapixel Histopathological Images</papertitle>
                </a>
                <br>
                Weiyi Wu, <strong>Xingjian Diao</strong>, Chongyang Gao, Xinwen Xu, Siting Li, Jiang Gui
                <br>
                <em>arXiv</em>, 2025
              </td>
            </tr>


             <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/LLMs_Design_Choices.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://d197for5662m48.cloudfront.net/documents/publicationstatus/264594/preprint_pdf/b9443b42f8c0c3cc6b063e558c77b48d.pdf" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>On The Design Choices of Next Level LLMs</papertitle>
                </a>
                <br>
                Yijun Tian, <strong>Xingjian Diao</strong>, Ming Cheng, Chunhui Zhang, Jiang Gui, Soroush Vosoughi, Xiangliang Zhang, Nitesh V. Chawla, Shichao Pei
                <br>
                <em>arXiv</em>, 2025
              </td>
            </tr>



            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/Survey4MusicAVQA.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2505.20638" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>Music's Multimodal Complexity in AVQA: Why We Need More than General Multimodal LLMs</papertitle>
                </a>
                <br>
                Wenhao You<sup>*</sup>, <strong>Xingjian Diao</strong><sup>*</sup>, Chunhui Zhang, Keyi Kong, Weiyi Wu, Zhongyu Ouyang, Chiyu Ma, Tingxuan Wu, Noah Wei, Zong Ke, Ming Cheng, Soroush Vosoughi, Jiang Gui
                <br>
                <em>arXiv</em>, 2025
              </td>
            </tr>
            

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/judging-the-judges.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2406.07791" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>Judging the Judges: A Systematic Study of Position Bias in LLM-as-a-Judge</papertitle>
                </a>
                <br>
                Lin Shi, Chiyu Ma, Wenhua Liang, <strong>Xingjian Diao</strong>, Weicheng Ma, Soroush Vosoughi
                <br>
                <em>arXiv</em>, 2025
              </td>
            </tr>



            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/emnlp24_Amuse.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://aclanthology.org/2024.findings-emnlp.159.pdf" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>Learning Musical Representations for Music Performance Question Answering</papertitle>
                </a>
                <br>
                <strong>Xingjian Diao</strong>, Chunhui Zhang, Tingxuan Wu, Ming Cheng, Zhongyu Ouyang, Weiyi Wu, Jiang Gui
                <br>
                <em>Conference on Empirical Methods in Natural Language Processing (EMNLP 2024) Findings</em>
                <br>
                <span style="color: gold; font-size: 24px;">&#x1F396; </span> <span style="color: 	#DAA520; font-size: 15px;">Biomedical Data Science Travel Award, Dartmouth College</span>
              </td>
            </tr>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/AlphaExpert_emnlp24.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://aclanthology.org/2024.emnlp-main.1141.pdf" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>AlphaExpert: Assigning LoRA Experts Based on Layer Training Quality</papertitle>
                </a>
                <br>
                Peijun Qing, Chongyang Gao, Yefan Zhou, <strong>Xingjian Diao</strong>, Yaoqing Yang, Soroush Vosoughi
                <br>
                <em>Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2024
              </td>
            </tr>



            <!-- <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/vibration_solutions.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://www.worldscientific.com/doi/abs/10.1142/S0219455425502669" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>Analytical free vibration solutions of rectangular thin plates subjected to three edges rotationally-restrained and one edge free</papertitle>
                </a>
                <br>
                Jinghui Zhang, Pin Gao, <strong>Xingjian Diao</strong>, Salamat Ullah, Jiapeng Li, Yuwei Zhang, Wenyue Qi
                <br>
                <em>International Journal of Structural Stability and Dynamics (IJSSD)</em>, 2024
                <br>
              </td>
            </tr>  -->



            <!-- <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/SAIC.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://link.springer.com/chapter/10.1007/978-3-031-63592-2_22" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>SAIC: Integration of Speech Anonymization and Identity Classification</papertitle>
                </a>
                <br>
                Ming Cheng<sup>*</sup>, <strong>Xingjian Diao</strong><sup>*</sup>, Shitong Cheng, Wenjun Liu
                <br>
                <em>AI for Health Equity and Fairness: Leveraging AI to Address Social Determinants of Health</em>, Cham: Springer Nature Switzerland, 2024
                <br>
              </td>
            </tr> -->


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/publications/glumarker.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/document/10782165" target="_blank" style="color:#4169E1; text-decoration: none;">
                <papertitle>GluMarker: A Novel Predictive Modeling of Glycemic Control Through Digital Biomarkers</papertitle>
              </a>
              <br>
              Ziyi Zhou<sup>*</sup>, Ming Cheng<sup>*</sup>, <strong>Xingjian Diao</strong><sup>*</sup>, Yanjun Cui, Xiangling Li
              <br>
              <em>Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)</em>, 2024 <font color="#E55C5C"><strong>(Lecture Presentation)</strong></font>
              <br>
              <span style="color: gold; font-size: 24px;">&#x1F396; </span> <span style="color: 	#DAA520; font-size: 15px;"> IEEE EMBC NextGen Scholar Award</span>
            </td>
          </tr>

          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/publications/Efflex.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2404.12400" target="_blank" style="color:#4169E1; text-decoration: none;">
                <papertitle>Efflex: Efficient and Flexible Pipeline for Spatio-Temporal Trajectory Graph
                  Modeling and Representation Learning</papertitle>
              </a>
              <br>
              Ming Cheng<sup>*</sup>, Ziyi Zhou<sup>*</sup>, Bowen Zhang<sup>*</sup>, Ziyu Wang, Jiaqi Gan, Ziang Ren, Weiqi Feng, Yi Lyu, Hefan Zhang, <strong>Xingjian Diao</strong>
              <br>
              <em>Conference on Computer Vision and Pattern Recognition (CVPR) </em><a target="_blank" style="color:#4169E1; text-decoration: none;"><em>SG2RL2024</em></a>, 2024
              <br>
            </td>
          </tr> -->

          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/publications/AV-MaskEnhancer.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/document/10356553" target="_blank" style="color:#4169E1; text-decoration: none;">
                <papertitle>AV-MaskEnhancer: Enhancing Video Representations through Audio-Visual Masked Autoencoder</papertitle>
              </a>
              <br>
              <strong>Xingjian Diao</strong><sup>*</sup>, Ming Cheng<sup>*</sup>, Shitong Cheng
              <br>
              <em>International Conference on Tools with Artificial Intelligence (ICTAI)</em>, 2023
              <br>
            </td>
          </tr> -->

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/publications/JBHI.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/document/10124956" target="_blank" style="color:#4169E1; text-decoration: none;">
                <papertitle>An End-to-End Energy-Efficient Approach for Intake Detection With Low Inference Time Using Wrist-Worn Sensor</papertitle>
              </a>
              <br>
              Boyang Wei, Shibo Zhang, <strong>Xingjian Diao</strong>, Qiuyang Xu, Yang Gao, Nabil Alshurafa
              <br>
              <em>IEEE Journal of Biomedical and Health Informatics (JBHI)</em>, 2023
            </td>
          </tr>

        </tbody></table>
          
      </div>
    </section>




    <section id="Projects" class="showcase">
      <div class="showcase-left">
        <div class="showcase-left-title">Projects</div>
        <div class="showcase-left-desc">Selected Projects</div>
      </div>

      <div class="showcase-right">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./proj_pic/MccApp.jpg" width="200" height="120">
            </td>        
            <td width="75%" valign="middle">
                <papertitle><strong>Intake Detection Tool with Multiple Classifiers</strong></papertitle>
              <p>An Android application for wrist-worn devices to detect feeding patterns with low energy consumption and fast inference times. It applied template-based multi-centroid classifier which could provide an end-to-end battery-efficient approach for feeding detection.</p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./proj_pic/activeLearning.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
                <papertitle><strong>Interactive Active Learning Annotation Tool</strong></papertitle>
              <p>An interactive annotation software that utilizes active learning to reduce data labeling time and cost. The front-end was created with PyQt5 and pyqtgraph, offering features such as time synchronization and video frame-by-frame rewinding. The back-end, utilizing cv2, sklearn and xgboost, performed data processing, K-means clustering, and clustered entropy active learning.</p>
            </td>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./proj_pic/iPADshiny.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
                <papertitle><strong>iPADshiny</strong></papertitle>
              <p>iPADshiny (integrated Protein Array Data management,analysis and visualization tools) is a desktop application that simplifies protein analysis for biologists. It integrates multiple algorithms, including the auto-antibody Profiling Analysis, and utilizes state-of-the-art computational methods for efficient and effective analysis.</p>
            </td>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./proj_pic/drawingSys.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
                <papertitle><strong>Online Drawing Management System</strong></papertitle>
              <p>An Online Drawing Management System with B/S structure and Windows OS, including features such as notice announcement, navigation menu, user and role management, flexible authorization, and online management and preview of large drawing documents. It automatically loads existing document storage structures, eliminating the need for manual entry of basic information. (Copyright: 2018SR071476)</p>
            </td>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./proj_pic/Remote_Voting_System.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
                <papertitle><strong>Remote Voting System</strong></papertitle>
              <p>A remote voting system that uses SMS texts to count unique votes while recording phone numbers to prevent repetitive voting, offering an accessible and transparent solution for remote voting scenarios.</p>
            </td>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./proj_pic/introvert.jpeg" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
                <papertitle><strong>Introvert</strong></papertitle>
              <p>An inclusive online chat environment for introverted students, utilizing JavaScript, Python, and Google Cloud platform to implement anonymous chatting and user-friendly direct messaging features, aimed at promoting engagement and improving the chat experience for introverted individuals.</p>
            </td>
            </td>
          </tr>
          </tbody></table>
      </div>
    </section>



    <section id="Teaching" class="showcase">
      <div class="showcase-left">
        <div class="showcase-left-title">Teaching</div>
        <div class="footnote">
            <p>TA indicates Teaching Assistant</p>
        </div>
      </div>
      <div class="showcase-right">
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:30px;width:25%;vertical-align:middle">
              <img src="images/dartmouth_logo.png" width="120">
            </td>
            <td width="75%" valign="center">
              <a>Graduate TA, Video Understanding, <a href="https://dartmouth.smartcatalogiq.com/en/current/orc/departments-programs-undergraduate/computer-science/cosc-computer-science-undergraduate/cosc-89-30/" target="_blank" style="color:#4169E1; text-decoration: none;">CS89/189</a>, Spring 2024</a>
              <br>
              <a>Graduate TA, Machine Learning, <a href="https://dartmouth.smartcatalogiq.com/en/current/orc/departments-programs-undergraduate/computer-science/cosc-computer-science-undergraduate/cosc-74/" target="_blank" style="color:#4169E1; text-decoration: none;">CS74/274</a>, Winter 2024</a>
              <br>
              <a>Graduate TA, Database Systems, <a href="https://dartmouth.smartcatalogiq.com/en/current/orc/departments-programs-undergraduate/computer-science/cosc-computer-science-undergraduate/cosc-61/" target="_blank" style="color:#4169E1; text-decoration: none;">COSC61</a>, Summer 2023</a>
              <br>
              <a>Graduate TA, Object Oriented Programming, <a href="https://dartmouth.smartcatalogiq.com/en/current/orc/departments-programs-undergraduate/computer-science/cosc-computer-science-undergraduate/cosc-10/" target="_blank" style="color:#4169E1; text-decoration: none;">COSC10</a>, Spring 2023</a>
              <br>
              <a>Graduate TA, Applied Cryptography, <a href="https://dartmouth.smartcatalogiq.com/en/current/orc/departments-programs-undergraduate/computer-science/cosc-computer-science-undergraduate/cosc-62/" target="_blank" style="color:#4169E1; text-decoration: none;">COSC62/162</a>, Winter 2023</a>
              <br>
              <a>Graduate TA, Object Oriented Programming, <a href="https://www.cs.dartmouth.edu/~albertoq/cs10/" target="_blank" style="color:#4169E1; text-decoration: none;">COSC10</a>, Fall 2022</a>
            </td>
          </tr>
        </tbody></table>
      </div>
    </section>

    <section id="Services" class="showcase">
      <div class="showcase-left">
        <div class="showcase-left-title">Services</div>
      </div>
      <div class="showcase-right">
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding: 30px; width: 25%; vertical-align: middle; font-weight: bold; font-size: 18px; text-align: left; color: #444;">
              Served as Reviewer:
            </td>

            <td width="75%" valign="center">
              <a>ACM International Conference on Multimedia (ACMMM Datasets Track) </a>
              <br>
              <a>ACM International Conference on Multimedia (ACMMM) </a>
              <br>
              <a>Annual Conference on Neural Information Processing Systems (NeurIPS) </a>
              <br>
              <a>International Conference on Computer Vision (ICCV) </a>
              <br>
              <a>Conference on Empirical Methods in Natural Language Processing (EMNLP) </a>
              <br>
              <a>Annual Meeting of the Association for Computational Linguistics (ACL Industry Track) </a>
              <br>
              <a>Annual Meeting of the Association for Computational Linguistics (ACL) </a>
              <br>
              <a>Conference on Computer Vision and Pattern Recognition (CVPR) </a>
              <br>
              <a>International Conference on Learning Representations (ICLR) </a>
              <br>
              <a>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) </a>
              <br>
              <a>International Conference on Artificial Intelligence and Statistics (AISTATS) </a>
              <br>
              <a>ACM International Conference on Intelligent User Interfaces (IUI) </a>
              <br>
              <a>International Conference on Acoustics, Speech & Signal Processing (ICASSP) </a>
              <br>
              <a>IEEE International Symposium on Biomedical Imaging (ISBI) </a>
              <br>
              <a>International Joint Conference on Neural Networks (IJCNN) </a>
              <br>
              <a>IEEE International Conference on Multimedia & Expo (ICME) </a>
              <br>
              <a>IEEE International Conference on Advanced Visual and Signal-Based Systems (AVSS) </a>
              <br>
              <a>NeurIPS Workshop on Foundation Model Interventions (MINT 2024) </a>
              <br>
              
            </td>
          </tr>
        </tbody></table>
      </div>
    </section>
    
    <section id="Contact" class="showcase">
      <div class="showcase-left">
        <div class="showcase-left-title">Contact</div>
      </div>
      <div class="showcase-right">
        <ul class="contact-ul">
          <li class="contact-item"><img class="contact-svg" src="./svg_icons/email-svgrepo-com2.svg" alt=""><a href="mailto:xingjian.diao.gr@dartmouth.edu">xingjian.diao.gr@dartmouth.edu</a></li>
        </ul>
      </div>
    </section>
    <footer>Xingjian Diao ¬© 2025, referring to the <a href="https://github.com/jonbarron/jonbarron_website" target="_blank" style="color:#4169E1; text-decoration: none;">website template</a></footer>
  </div>
</body>
</html>
