<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="./index.css">
  <link rel="icon" type="image/png" href="images/dartmouth_logo.jpeg">
  <title>Xingjian Diao</title>
</head>
<body>
  <div class="content" style="display: block;">
    <nav class="nav1-show">
      <a href="index.html"><h2 class="title">Xingjian's Website</h2></a>
      <ul class="nav-ul">
        <li class="nav-item"><a href="#">Biography</a></li>
        <li class="nav-item"><a href="#Publications">Publications</a></li>
        <li class="nav-item"><a href="#Projects">Projects</a></li>
        <!-- <li class="nav-item"><a href="./Xingjian_CV.pdf">CV</a></li> -->
        <li class="nav-item"><a href="#Teaching">Teaching</a></li>
        <li class="nav-item"><a href="#Services">Services</a></li>
        <li class="nav-item"><a href="#Contact">Contact</a></li>
      </ul>
    </nav>
    <nav class="nav2-show">
      <a href="index.html"><h2 class="title">Xingjian's Website</h2></a>
    </nav>
    <ul class="nav-ul">
      <!-- <li class="nav-item"> <strong><a style="color:#2910a5; text-decoration: none;" href="#">Biography</a></strong></li> -->
      <li class="nav-item"> <strong><a style="color:#9f202a; text-decoration: none;" href="#Publications">Publications</a></strong></li>
      <li class="nav-item"> <strong><a style="color:#9f202a; text-decoration: none;" href="#Projects">Projects</a></strong></li>
      <!-- <li class="nav-item"><a href="./Xingjian_CV.pdf">CV</a></li> -->
       <li class="nav-item"> <strong><a style="color:#9f202a; text-decoration: none;" href="#Teaching">Teaching</a></strong></li>
       <li class="nav-item"> <strong><a style="color:#9f202a; text-decoration: none;" href="#Services">Services</a></strong></li>
       <!-- <li class="nav-item"> <strong><a style="color:#010616; text-decoration: none;" href="#Contact">Contact</a></strong></li> -->
    </ul>
    <section class="body">
      <div class="left">
        <div class="head-img"></div>
        <h1 class="name">Xingjian Diao</h1>
        <!-- <h3 class="desc2" style="color: black;">刁行健</h4> -->
<!--         <h3 class="desc2">Capricorns</h3> <br> -->
      
        <ul class="icon">
          <li class="icon-item"><a href="mailto:xingjian.diao.gr@dartmouth.edu"><img src="./svg_icons/email-svgrepo-com.svg" alt=""></a></li>
          <li class="icon-item"><img src="./svg_icons/icons8-linkedin.svg" alt="" onclick="window.location.href='http:\/\/www.linkedin.com/in/xingjian-diao-a5637814a/'"></li>
          <!-- <li class="icon-item"><img src="./svg_icons/researchgate-logo-svgrepo-com.svg" alt="" onclick="window.location.href='http:\/\/researchgate.net/profile/Xingjian_Diao/'"></li> -->
          <li class="icon-item"><img src="./svg_icons/icons8-google-scholar.svg" alt="" onclick="window.location.href='https:\/\/scholar.google.com/citations?user=-U2KzpYAAAAJ&hl=en'"></li>
          <!-- <li class="icon-item"><img src="./svg_icons/curriculum-vitae-resume-svgrepo-com.svg" alt="" onclick="window.location.href='./Xingjian_CV.pdf'" ></li> -->

        </ul>
      </div>
      <div class="right">
        <h1 class="biography-title">About Me</h1>
        <br><br>
        <section class="biography">
          <!-- I focus my research on <b>Multimodal Learning</b> as it has numerous practical applications that can benefit society in various ways.
           I am excited to carry out advanced research focused on training sophisticated, trustworthy, 
           and high-quality machine learning models that can better interpret and comprehend the audio-visual world. -->
        <p>I am currently a Ph.D. student at <a href="https://web.cs.dartmouth.edu/" style="color:#4169E1; text-decoration: none;">Dartmouth College</a>. 
          My research interests focus on <strong>multimodal learning</strong>. 
          I have published papers and developed codes for 
          temporal modeling, efficient training, and audio-video-language integration, advancing state-of-the-art 
          <strong>multimodal large language models</strong> (MLLMs) in audio-visual question answering, video captioning, 
          and text-to-talking face generation.</p>

          <!-- <p>I am currently a Ph.D. student at <a href="https://web.cs.dartmouth.edu/" style="color:#4169E1; text-decoration: none;">Dartmouth College</a>. 
            I have published papers and developed codes for 
            temporal modeling, efficient training, and audio-video-language integration, advancing state-of-the-art 
            <strong>multimodal large language models</strong> (MLLMs) in audio-visual question answering, video captioning, 
            and text-to-talking face generation. My research interests focus on <strong>multimodal learning</strong>, particularly developing 
            sophisticated models that can effectively process and align signals across vision, language and audio domains to advance 
            real-world AI applications benefiting society.</p> -->
          
        <br><p>Prior to Dartmouth, I earned a Master's degree in Computer Science from Northwestern University (2021), advised by Prof. <a href="https://habitslab.github.io/" style="color:#4169E1; text-decoration: none;">Nabil Alshurafa</a> (<span style="color: #e141cc;">Thank you, Nabil!</span>), and a B.S. degree in Computer Science from the University of Pittsburgh (2020).</p>
      </section>
        <br><br>
        <section class="other-info">
          <div class="interests">
            <h2>Interests</h2>
            <ul class="interests-ul">
              <li class="interests-item">Multimodal Large Language Models</li>
              <li class="interests-item">Video Understanding</li>
              <li class="interests-item">Natural Language and Speech Processing</li>
            </ul>
          </div>
          <div class="education">
            <h2>Education</h2>
            <ul class="education-ul">
              <li class="education-item">
                <img src="./svg_icons/graduation-cap.svg">
                <div class="education-desc">
                  <div class="time">Ph.D. in Computer Science, -Present</div>
                  <div class="school">Dartmouth College</div>
                </div>
              </li>
              <li class="education-item">
                <img src="./svg_icons/graduation-cap.svg">
                <div class="education-desc">
                  <div class="time">M.S. in Computer Science, 2021</div>
                  <div class="school">Northwestern University</div>
                </div>
              </li>
              <li class="education-item">
                <img src="./svg_icons/graduation-cap.svg">
                <div class="education-desc">
                  <div class="time">B.S. in Computer Science, 2020</div>
                  <div class="school">University of Pittsburgh</div>
                </div>
              </li>
            </ul>
          </div>
        </section>
      </div>
    </section>
    <section id="Publications" class="showcase">
      <div class="showcase-left">
        <div class="showcase-left-title">Publications</div>
<!--         <div class="showcase-left-desc">Selected publications</div> -->
        <div class="footnote">
            <p><sup>*</sup> indicates equal contribution</p>
        </div>
      </div>
      <div class="showcase-right">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            <!-- <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/Sparsify.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>Temporal Working Memory: Query-Guided Temporal Segment Refinement for Enhanced Multimodal Understanding</papertitle>
                </a>
                <br>
                <strong>Xingjian Diao</strong>, Tianzhen Yang, Chunhui Zhang, Weiyi Wu, Ming Cheng, Jiang Gui
                <br>
                <em>Annual Meeting of the Association for Computational Linguistics (ACL) </em>, 2025
              </td>
            </tr> -->

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/TWM.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://xid32.github.io/images/publications/Temporal_Working_Memory.pdf" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>Query-Guided Temporal Segment Refinement for Enhanced Multimodal Understanding</papertitle>
                </a>
                <br>
                <strong>Xingjian Diao</strong><sup>*</sup>, Chunhui Zhang<sup>*</sup>, Weiyi Wu, 
                Zhongyu Ouyang, Peijun Qing, Ming Cheng, Soroush Vosoughi, Jiang Gui
                <br>
                <em>NAACL Findings (long paper)</em>, 2025
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/FT2TF.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/pdf/2312.05430" style="color:#4169E1; text-decoration: none;">
                  <papertitle>FT2TF: First-Person Statement Text-To-Talking Face Generation</papertitle>
                </a>
                <br>
                <strong>Xingjian Diao</strong>, Ming Cheng, Wayner Barrios, SouYoung Jin
                <br>
                <em>Winter Conference on Applications of Computer Vision (WACV) </em>, 2025
                <br>
              </td>
            </tr>

             <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/amuse_emnlp.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://aclanthology.org/2024.findings-emnlp.159.pdf" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>Learning Musical Representations for Music Performance Question Answering</papertitle>
                </a>
                <br>
                <strong>Xingjian Diao</strong>, Chunhui Zhang, Tingxuan Wu, Ming Cheng, Zhongyu Ouyang, Weiyi Wu, Jiang Gui
                <br>
                <em>EMNLP Findings (long paper)</em>, 2024
                <br>
              </td>
            </tr>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/AlphaExpert_emnlp24.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://aclanthology.org/2024.emnlp-main.1141.pdf" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>AlphaExpert: Assigning LoRA Experts Based on Layer Training Quality</papertitle>
                </a>
                <br>
                Peijun Qing, Chongyang Gao, Yefan Zhou, <strong>Xingjian Diao</strong>, Yaoqing Yang, Soroush Vosoughi
                <br>
                <em>Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2024
                <br>
                <p></p>
              </td>
            </tr>



            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/vibration_solutions.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://www.worldscientific.com/doi/abs/10.1142/S0219455425502669" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>Analytical free vibration solutions of rectangular thin plates subjected to three edges rotationally-restrained and one edge free</papertitle>
                </a>
                <br>
                Jinghui Zhang, Pin Gao, <strong>Xingjian Diao</strong>, Salamat Ullah, Jiapeng Li, Yuwei Zhang, Wenyue Qi
                <br>
                <em>International Journal of Structural Stability and Dynamics (IJSSD)</em>, 2024
                <br>
              </td>
            </tr> 



            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/publications/SAIC.png" width="200" height="120">
              </td>
              <td width="75%" valign="middle">
                <a href="https://link.springer.com/chapter/10.1007/978-3-031-63592-2_22" target="_blank" style="color:#4169E1; text-decoration: none;">
                  <papertitle>SAIC: Integration of Speech Anonymization and Identity Classification</papertitle>
                </a>
                <br>
                Ming Cheng<sup>*</sup>, <strong>Xingjian Diao</strong><sup>*</sup>, Shitong Cheng, Wenjun Liu
                <br>
                <em>AI for Health Equity and Fairness: Leveraging AI to Address Social Determinants of Health</em>, Cham: Springer Nature Switzerland, 2024
                <br>
              </td>
            </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/publications/glumarker.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2404.12605" target="_blank" style="color:#4169E1; text-decoration: none;">
                <papertitle>GluMarker: A Novel Predictive Modeling of Glycemic Control Through Digital Biomarkers</papertitle>
              </a>
              <br>
              Ziyi Zhou<sup>*</sup>, Ming Cheng<sup>*</sup>, <strong>Xingjian Diao</strong><sup>*</sup>, Yanjun Cui, Xiangling Li
              <br>
              <em>Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)</em>, 2024
              <br>
              <span style="color: gold; font-size: 24px;">&#x1F396; </span> <span style="color: 	#DAA520; font-size: 17px;"> IEEE EMBC NextGen Scholar Award</span>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/publications/Efflex.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2024W/SG2RL/papers/Cheng_Efflex_Efficient_and_Flexible_Pipeline_for_Spatio-Temporal_Trajectory_Graph_Modeling_CVPRW_2024_paper.pdf" target="_blank" style="color:#4169E1; text-decoration: none;">
                <papertitle>Efflex: Efficient and Flexible Pipeline for Spatio-Temporal Trajectory Graph
                  Modeling and Representation Learning</papertitle>
              </a>
              <br>
              Ming Cheng<sup>*</sup>, Ziyi Zhou<sup>*</sup>, Bowen Zhang<sup>*</sup>, Ziyu Wang, Jiaqi Gan, Ziang Ren, Weiqi Feng, Yi Lyu, Hefan Zhang, <strong>Xingjian Diao</strong>
              <br>
              <em>Conference on Computer Vision and Pattern Recognition (CVPR) </em><a target="_blank" style="color:#4169E1; text-decoration: none;"><em>SG2RL2024</em></a>, 2024
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/publications/AV-MaskEnhancer.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/document/10356553" target="_blank" style="color:#4169E1; text-decoration: none;">
                <papertitle>AV-MaskEnhancer: Enhancing Video Representations through Audio-Visual Masked Autoencoder</papertitle>
              </a>
              <br>
              <strong>Xingjian Diao</strong><sup>*</sup>, Ming Cheng<sup>*</sup>, Shitong Cheng
              <br>
              <em>International Conference on Tools with Artificial Intelligence (ICTAI)</em>, 2023
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/publications/JBHI.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/document/10124956" target="_blank" style="color:#4169E1; text-decoration: none;">
                <papertitle>An End-to-End Energy-Efficient Approach for Intake Detection With Low Inference Time Using Wrist-Worn Sensor</papertitle>
              </a>
              <br>
              Boyang Wei, Shibo Zhang, <strong>Xingjian Diao</strong>, Qiuyang Xu, Yang Gao, Nabil Alshurafa
              <br>
              <em>IEEE Journal of Biomedical and Health Informatics (JBHI)</em>, 2023 
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/publications/CES.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/document/9089176" target="_blank" style="color:#4169E1; text-decoration: none;">
                <papertitle>Building a Cloud-based Energy Storage System through Digital Transformation of Distributed Backup Batteries in Mobile Base Stations</papertitle>
              </a>
              <br>
              Song Ci, Yanglin Zhou, Yuan Xu, <strong>Xingjian Diao</strong>, Junwei Wang
              <br>
              <em>China Communications</em>, 2020
              <br>
            </td>
          </tr>


          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/publications/waste.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.preprints.org/manuscript/202002.0327/v1" target="_blank" style="color:#4169E1; text-decoration: none;">
                <papertitle>Reach on Waste Classification and Identification by Transfer Learning and Lightweight Neural Network</papertitle>
              </a>
              <br>
              Xiujie Xu, Xuehai Qi, <strong>Xingjian Diao</strong>
              <br>
              <em>Preprints</em>, 2020
              <br>
              <p></p>
            </td> -->
          </tr>

        </tbody></table>
          
      </div>
    </section>
    <section id="Projects" class="showcase">
      <div class="showcase-left">
        <div class="showcase-left-title">Projects</div>
        <div class="showcase-left-desc">Selected Projects</div>
      </div>

      <div class="showcase-right">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./proj_pic/MccApp.jpg" width="200" height="120">
            </td>        
            <td width="75%" valign="middle">
                <papertitle><strong>Intake Detection Tool with Multiple Classifiers</strong></papertitle>
              <p>An Android application for wrist-worn devices to detect feeding patterns with low energy consumption and fast inference times. It applied template-based multi-centroid classifier which could provide an end-to-end battery-efficient approach for feeding detection.</p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./proj_pic/activeLearning.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
                <papertitle><strong>Interactive Active Learning Annotation Tool</strong></papertitle>
              <p>An interactive annotation software that utilizes active learning to reduce data labeling time and cost. The front-end was created with PyQt5 and pyqtgraph, offering features such as time synchronization and video frame-by-frame rewinding. The back-end, utilizing cv2, sklearn and xgboost, performed data processing, K-means clustering, and clustered entropy active learning.</p>
            </td>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./proj_pic/iPADshiny.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
                <papertitle><strong>iPADshiny</strong></papertitle>
              <p>iPADshiny (integrated Protein Array Data management,analysis and visualization tools) is a desktop application that simplifies protein analysis for biologists. It integrates multiple algorithms, including the auto-antibody Profiling Analysis, and utilizes state-of-the-art computational methods for efficient and effective analysis.</p>
            </td>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./proj_pic/drawingSys.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
                <papertitle><strong>Online Drawing Management System</strong></papertitle>
              <p>An Online Drawing Management System with B/S structure and Windows OS, including features such as notice announcement, navigation menu, user and role management, flexible authorization, and online management and preview of large drawing documents. It automatically loads existing document storage structures, eliminating the need for manual entry of basic information. (Copyright: 2018SR071476)</p>
            </td>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./proj_pic/Remote_Voting_System.png" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
                <papertitle><strong>Remote Voting System</strong></papertitle>
              <p>A remote voting system that uses SMS texts to count unique votes while recording phone numbers to prevent repetitive voting, offering an accessible and transparent solution for remote voting scenarios.</p>
            </td>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./proj_pic/introvert.jpeg" width="200" height="120">
            </td>
            <td width="75%" valign="middle">
                <papertitle><strong>Introvert</strong></papertitle>
              <p>An inclusive online chat environment for introverted students, utilizing JavaScript, Python, and Google Cloud platform to implement anonymous chatting and user-friendly direct messaging features, aimed at promoting engagement and improving the chat experience for introverted individuals.</p>
            </td>
            </td>
          </tr>
          </tbody></table>

       <!--  
        <h4 class="teaching-title project-title">Introvert Chatting Platform</h4>
        <ul class="teaching project-ul">
          <li class="teaching-item project-li">An inclusive online chat environment for introverted students, utilizing JavaScript, Python, and Google Cloud platform to implement anonymous chatting and user-friendly direct messaging features, aimed at promoting engagement and improving the chat experience for introverted individuals.</li>
          <li><img alt="" srcset="" onclick="window.location.href='https:\/\/github.com/xid32/Introvert-Software-Engineering'" src="./proj_pic/introvert.jpeg" style="width: 300px;height: 200px;"></li>
        </ul>
        <button class="view-more" onclick="window.location.href='https:\/\/github.com/xid32/Introvert-Software-Engineering'">View More</button> -->
      </div>
    </section>



    <section id="Teaching" class="showcase">
      <div class="showcase-left">
        <div class="showcase-left-title">Teaching</div>
        <div class="footnote">
            <p>TA indicates Teaching Assistant</p>
        </div>
      </div>
      <div class="showcase-right">
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:30px;width:25%;vertical-align:middle">
              <img src="images/dartmouth_logo.png" width="120">
            </td>
            <td width="75%" valign="center">
              <a>Graduate TA, Video Understanding, <a href="https://dartmouth.smartcatalogiq.com/en/current/orc/departments-programs-undergraduate/computer-science/cosc-computer-science-undergraduate/cosc-89-30/" target="_blank" style="color:#4169E1; text-decoration: none;">CS89/189</a>, Spring 2024</a>
              <br>
              <a>Graduate TA, Machine Learning, <a href="https://dartmouth.smartcatalogiq.com/en/current/orc/departments-programs-undergraduate/computer-science/cosc-computer-science-undergraduate/cosc-74/" target="_blank" style="color:#4169E1; text-decoration: none;">CS74/274</a>, Winter 2024</a>
              <br>
              <a>Graduate TA, Database Systems, <a href="https://dartmouth.smartcatalogiq.com/en/current/orc/departments-programs-undergraduate/computer-science/cosc-computer-science-undergraduate/cosc-61/" target="_blank" style="color:#4169E1; text-decoration: none;">COSC61</a>, Summer 2023</a>
              <br>
              <a>Graduate TA, Object Oriented Programming, <a href="https://dartmouth.smartcatalogiq.com/en/current/orc/departments-programs-undergraduate/computer-science/cosc-computer-science-undergraduate/cosc-10/" target="_blank" style="color:#4169E1; text-decoration: none;">COSC10</a>, Spring 2023</a>
              <br>
              <a>Graduate TA, Applied Cryptography, <a href="https://dartmouth.smartcatalogiq.com/en/current/orc/departments-programs-undergraduate/computer-science/cosc-computer-science-undergraduate/cosc-62/" target="_blank" style="color:#4169E1; text-decoration: none;">COSC62/162</a>, Winter 2023</a>
              <br>
              <a>Graduate TA, Object Oriented Programming, <a href="https://www.cs.dartmouth.edu/~albertoq/cs10/" target="_blank" style="color:#4169E1; text-decoration: none;">COSC10</a>, Fall 2022</a>
            </td>
          </tr>
        </tbody></table>
      </div>
    </section>

    <section id="Services" class="showcase">
      <div class="showcase-left">
        <div class="showcase-left-title">Services</div>
        <!-- <div class="footnote">
            <p>TA indicates Teaching Assistant</p>
        </div> -->
      </div>
      <div class="showcase-right">
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding: 30px; width: 25%; vertical-align: middle; font-weight: bold; font-size: 18px; text-align: left; color: #444;">
              Served as Reviewer:
            </td>

            <td width="75%" valign="center">
              <a>Conference on Computer Vision and Pattern Recognition (CVPR) </a>
              <br>
              <a>International Conference on Learning Representations (ICLR) </a>
              <br>
              <a>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) </a>
              <br>
              <a>International Conference on Acoustics, Speech & Signal Processing (ICASSP) </a>
              <br>
              <a>NeurIPS - Workshop on Foundation Model Interventions (MINT 2024) </a>
              <br>
              <a>IEEE International Symposium on Biomedical Imaging (ISBI) </a>
              <br>
              <a>International Joint Conference on Neural Networks (IJCNN) </a>
              <br>
              <a>IEEE International Conference on Multimedia & Expo (ICME) </a>
              <br>
              
            </td>
          </tr>
        </tbody></table>
      </div>
    </section>
    
    <section id="Contact" class="showcase">
      <div class="showcase-left">
        <div class="showcase-left-title">Contact</div>
      </div>
      <div class="showcase-right">
        <ul class="contact-ul">
          <li class="contact-item"><img class="contact-svg" src="./svg_icons/email-svgrepo-com2.svg" alt=""><a href="mailto:xingjian.diao.gr@dartmouth.edu">xingjian.diao.gr@dartmouth.edu</a></li>
          <!-- <li class="contact-item"><img class="contact-svg" src="./svg_icons/phone-svgrepo-com.svg" alt=""><a href="#Contact">Phone Number</a></li>
          <li class="contact-item"><img class="contact-svg" src="./svg_icons/house-home-svgrepo-com.svg" alt="">Hanover</li>
          <li class="contact-item"><img class="contact-svg" src="./svg_icons/instagram-svgrepo-com.svg" alt=""><a href="https://www.instagram.com/diaoxingjian/">View Xingjian's Instagram</a></li> -->
        </ul>
      </div>
    </section>
    <footer>Xingjian Diao © 2025, referring to the <a href="https://github.com/jonbarron/jonbarron_website" target="_blank" style="color:#4169E1; text-decoration: none;">website template</a></footer>
  </div>
</body>
</html>
